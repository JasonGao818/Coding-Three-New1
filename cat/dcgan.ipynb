{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bbYicw0MYWw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data, crop, and resize"
      ],
      "metadata": {
        "id": "ow8hIWJVMbSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(image_folder='data/cat_v1'):\n",
        "\n",
        "    target_size = 512\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        image = Image.open(image_path)\n",
        "        width, height = image.size\n",
        "        shorter_side = min(width, height)\n",
        "        left = (width - shorter_side) // 2\n",
        "        top = (height - shorter_side) // 2\n",
        "        right = (width + shorter_side) // 2\n",
        "        bottom = (height + shorter_side) // 2\n",
        "        cropped_image = image.crop((left, top, right, bottom))\n",
        "        resized_image = cropped_image.resize((target_size, target_size))\n",
        "        image_array = np.array(resized_image)\n",
        "        if len(image_array.shape) < 3 or image_array.shape[-1] != 3:\n",
        "            continue\n",
        "        data.append(image_array[np.newaxis, :, :, :])\n",
        "\n",
        "    data = np.concatenate(data, axis=0)\n",
        "    return data"
      ],
      "metadata": {
        "id": "MxXWO6XFMcid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define generator"
      ],
      "metadata": {
        "id": "XRw-WdoQMeH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(latent_dim):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Dense(4 * 4 * 256, input_dim=latent_dim))\n",
        "    model.add(layers.Reshape((4, 4, 256)))\n",
        "    model.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2DTranspose(16, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2DTranspose(8, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2DTranspose(8, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding=\"same\", activation=\"sigmoid\"))\n",
        "    return model"
      ],
      "metadata": {
        "id": "y4MXE_RoMddc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define discriminator"
      ],
      "metadata": {
        "id": "5JNE6QZFMgQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(8, kernel_size=4, strides=2, padding=\"same\", input_shape=(512, 512, 3)))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2D(16, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2D(32, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.01))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "    return model"
      ],
      "metadata": {
        "id": "upsteyNOMhvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# initilization"
      ],
      "metadata": {
        "id": "vY99GZgBMkRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 1024\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "generator_optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.2)\n",
        "discriminator_optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.2)\n",
        "\n",
        "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "J0qzsT4JMkGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define loss functions"
      ],
      "metadata": {
        "id": "mfxg5s2wMmxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "JvpN2NQzMnGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function to show generated images"
      ],
      "metadata": {
        "id": "V9cMZ-9gMoRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[i, :, :, :])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig(f\"saved/cat_v1/generated_images_epoch_{epoch + 1}.png\")\n",
        "    plt.show()\n",
        "    plt.clf()"
      ],
      "metadata": {
        "id": "U0Rvxy4BMpiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function to train the DCGAN"
      ],
      "metadata": {
        "id": "lWWwQkwgMqow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "\n",
        "    noise = tf.random.normal([batch_size, latent_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "ak0Bsxe8MskG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "UshvNp4lMuWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "X_train = load_data()\n",
        "X_train = (X_train.astype('float32')) / 255\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(X_train.shape[0]).batch(batch_size)\n",
        "\n",
        "\n",
        "epochs = 5000\n",
        "for epoch in range(epochs):\n",
        "    for image_batch in train_dataset:\n",
        "        train_step(image_batch)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        generate_and_save_images(generator, epoch, tf.random.normal([16, latent_dim]))\n",
        "        print(f\"Epoch {epoch + 1} completed.\")"
      ],
      "metadata": {
        "id": "BZK_1esaMvPk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
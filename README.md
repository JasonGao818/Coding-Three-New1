Ps:Because the file content is too large to upload to GitHub, so I uploaded the code part and the code run file and the result in batches, you can open the webpage by copying the link below to download and view one by one, thank you.

Github Link : https://github.com/JasonGao818/Coding-Three-New1

The final result of the project is based on further changes to the Gan function that I learnt in week 5, here is the basic content that I referenced.

https://git.arts.ac.uk/rfiebrink/ExploringMachineIntelligence_Spring2023/blob/main/week5/dcgan.ipynb

Below is the dataset I used for this assignment, you can download the images I used via this link:

https://www.kaggle.com/datasets/yapwh1208/cats-breed-dataset

Or you can download the full content of the images I used directly from the link below, I've uploaded everything to the cloud and you can also view it directly online:

https://www.dropbox.com/scl/fo/5nhh0ie4gsl2ya82dyw7j/h?dl=0&rlkey=slyep5hr81d81lxh4qua96p0g

) Because the process trained by the code is too large to upload to Github, I've also uploaded it to another cloud, which you can view directly online by clicking on the link:

https://www.dropbox.com/scl/fo/r0b0r6gl6511jn5llkekw/h?dl=0&rlkey=ot9iljmqizti72iwz1zub0dxg

Finally, there is a link to a finished presentation of the code as well as a link to a presentation of the results: https://youtu.be/IlopEVxszsA

As stated in [Goodfellow et al., 2014], the Gan function is most commonly used to increase the resolution of a blurred image, transforming a low resolution image into a high resolution version, so what I did to generate a blurred image of a cat through Gan again at first glance is not intuitive, but from the perspective of the nature of the image, I feel that reducing a clear image to a point to point relationship However, from the perspective of the nature of the image, I feel that reducing a clear image to a point-to-point relationship is more conducive to finding the expression of the image, as the image is not just a visual representation, but more of a vehicle for emotion and perception. A clear image is easy for the viewer to understand, while a blurred image can arouse the viewer's curiosity and speculation about the content of the image, forcing them to keep looking and understanding the hidden information in the image because of their own curiosity. Because everyone's experience is different, it may make the answer full of uncertainty, thus triggering more empathy.
As mentioned in Barthes (1980), blurred images can stimulate the viewers' imagination, when the image becomes less detailed, what each person sees depends on their imagination, and each person will stimulate their own imagination to interpret the image, giving the content of the image to the viewers, and each person keeps on filling up the image through their creativity, so that each person can find fun in the design.
And compared to clear images, blurred images are more pure, as mentioned in Elkins (1999). It removes unnecessary details compared to a clear image but retains the colours, shapes and textures of the image, allowing us to focus more on the whole picture by not limiting ourselves to the local area, and allowing the viewer to empathise by making what they see complete.
This method is making the image blurry, which may be contrary to its own usage, but I think it's kind of an exploration and experimentation of converting from clear to blurry images.

[1][Goodfellow et al., 2014]ï¼šGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).
[2][Barthes, R. (1980). Camera lucida: Reflections on photography]. Roland Barthes
[3][Elkins, J. (1999). The Domain of Images]. 
